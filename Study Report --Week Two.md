## Study Report --Week Two

#### 关于神经网络基础知识学习：

神经网络中每层对输入数据所做的具体操作保存在该层的权重（weight）中，其本质是一串数字。用术语来说，每层实现的变换由其权重来参数化（parameterize）。权重有时也被称为该层的参数（parameter）。在这种语境下，学习的意思是为神经网络的所有层找到一组权重值，使得该网络能够将每个示例输入与其目标正确地一一对应。但重点来了：一个深度神经网络可能包含数千万个参数。找到所有参数的正确取值可能是一项非常艰巨的任务，特别是考虑到修改某个参数值将会影响其他所有参数的行为。

损失函数（目标函数）：损失函数的输入是网络预测值与真实目标值（即你希望网络输出的
结果），然后计算一个距离值，衡量该网络在这个示例上的效果好坏。

##### 核方法（kernel method）一组分类算法

SVM：支持向量机

SVM 的目标是通过在属于两个不同类别的两组数据点之间找到良好决策边界。决策边界可以看作一条直线或一个平面，将训练数据划分为两块空间，分别对应于两个类别。

（1）将数据映射到一个新的高维表示，这时决策边界可以用一个超平面来表示。

（2）间隔最大化

决策树、随机森林、**梯度提升机**

梯度提升机：它使用了梯度提升方法，通过迭代地训练新模型来专门解决之前模型的弱点，从而改进任何机器学习模型的效果。将梯度提升技术应用于决策树时，得到的模型与随机森林具有相似的性质，但在绝大多数情况下效果都比随机森林要好。

神经网络的**转机**：

更好的神经层激活函数（activation function）。
更好的权重初始化方案（weight-initialization scheme），一开始使用逐层预训练的方法，不过这种方法很快就被放弃了。
更好的优化方案（optimization scheme），比如 RMSProp和 Adam。

在开始训练之前，我们将对数据进行**预处理**，将其变换为网络要求的形状，并缩放到所
有值都在[0, 1] 区间。

```python
network.compile(optimizer='rmsprop',
loss='categorical_crossentropy',
metrics=['accuracy'])
```

**准备图像数据：**

```python
train_images = train_images.reshape((60000, 28 * 28))
train_images = train_images.astype('float32') / 255
test_images = test_images.reshape((10000, 28 * 28))
test_images = test_images.astype('float32') / 255
```

**标量（0D张量）**

仅包含一个数字的张量叫作标量。张量的维度（dimension）通常叫作**轴**（axis）。标量张量有0 个轴（ndim == 0）。张量轴的个数也叫作**阶**（rank）。

**向量（1D张量）**

数字组成的数组叫作向量（vector）或一维张量（1D 张量）。一维张量只有一个轴。

例：

```python
>>> x = np.array([12, 3, 6, 14, 7])
>>> x
array([12, 3, 6, 14, 7])
>>> x.ndim
1
```

这个向量有5 个元素，所以被称为**5D 向量**。

**矩阵（2D 张量）**

向量组成的数组叫作矩阵（matrix）或二维张量（2D 张量）。矩阵有2 个轴（通常叫作行和
列）。可以将矩阵直观地理解为数字组成的矩形网格。

**3D 张量与更高维张量**

将多个矩阵组合成一个新的数组，可以得到一个3D 张量。将多个3D 张量组合成一个数组，可以创建一个4D 张量，以此类推。

##### 关键属性

张量是由三个关键属性来定义的：

1.轴的个数（阶，ndim）；2.形状；3.数据类型（注意，Numpy（以及大多数其他库）中不存在字符串张量，因为张量存储在预先分配的连续内存段中，而字符串的长度是可变的，无法用这种方式存储。）

**在Numpy 中操作张量**

选择张量的特定元素叫作张量切片（tensor slicing）。

下面这个例子选择第10~100 个数字（不包括第100 个），并将其放在形状为(90, 28,
28) 的数组中。

```python
>>>my_slice = train_images[10:100]
>>> print(my_slice.shape)
(90, 28, 28)
```

可以使用负数索引。与Python 列表中的负数索引类似，它表示**与当前轴终点的相对位置**。

在图像中心裁剪出14 像素×14 像素的区域：

```python
my_slice = train_images[:, 7:-7, 7:-7]
```

**数据批量的概念**

通常来说，深度学习中所有数据张量的第一个轴（0 轴，因为索引从0 开始）都是**样本轴**（samples axis，有时也叫样本维度）。在MNIST 的例子中，样本就是数字图像。

此外，深度学习模型不会同时处理整个数据集，而是将数据拆分成小批量。

![1583572537286](C:\Users\HP\AppData\Roaming\Typora\typora-user-images\1583572537286.png)

对于这种批量张量，第一个轴（0 轴）叫作批量轴（batch axis）或批量维度（batch imension）。
**常见的数据张量**

**向量数据：**2D 张量，形状为 (samples, features)。
**时间序列数据或序列数据：**3D 张量，形状为 (samples, timesteps, features)。
**图像：**4D张量，形状为(samples, height, width, channels)或(samples, channels,height, width)。
**视频：**5D张量，形状为(samples, frames, height, width, channels)或(samples,frames, channels, height, width)。



**向量数据：**

对于这种数据集，每个数据点都被编码为一个向量，因此一个数据批量就被编码为2D 张量（即向量组成的数组），其中第一个轴是**样本轴**，第二个轴是**特征轴**。